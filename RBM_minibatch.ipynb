{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import cPickle\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    x = np.clip( x, -500, 500 )\n",
    "\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "class RBM(object):\n",
    "\n",
    "    def __init__(self, n_visible, n_hidden, mbtsz, epochs, eta, mrate, np_rng, weightinit=0.001,\\\n",
    "               lambda1 = 1, lambda2 = 1, lambda3 = 1,lambda4 = 1, \\\n",
    "               p_A_vk = None,p_s_vk = None,p_Aj_vk= None,p_sj_vk = None):\n",
    "        \"\"\"\n",
    "        CD-k training of RBM with SGD + Momentum.\n",
    "        @param n_visible:   num of lexicon\n",
    "        @param n_hidden:    num of latent topics\n",
    "        @param epochs:      training epochs\n",
    "        @param eta:         learning rate\n",
    "        @param mrate:       momentum rate\n",
    "        @param mbtsz:       mini-batch size\n",
    "        @param np_rng:      instances of RandomState\n",
    "        @param weightinit:  scaling of random weight initialization\n",
    "        \"\"\"\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "        self.mbtsz = mbtsz\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.mrate = mrate\n",
    "        self.np_rng = np_rng\n",
    "        self.W = weightinit * np_rng.randn(n_visible, n_hidden)\n",
    "        self.vbias = weightinit * np_rng.randn(n_visible)\n",
    "        self.hbias = np.zeros((n_hidden))\n",
    "        # for momentum\n",
    "        self.mW = np.zeros((n_visible, n_hidden))\n",
    "        self.mvbias = np.zeros((n_visible))\n",
    "        self.mhbias = np.zeros((n_hidden))\n",
    "\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.lambda3 = lambda3\n",
    "        self.lambda4 = lambda4\n",
    "        self.p_A_vk = p_A_vk\n",
    "        self.p_s_vk = p_s_vk\n",
    "        self.p_Aj_vk = p_Aj_vk\n",
    "        self.p_sj_vk = p_sj_vk\n",
    "    def train(self, data):\n",
    "        for epoch in range(self.epochs):\n",
    "            print(epoch)\n",
    "            #self.np_rng.shuffle(data)\n",
    "            for i in range(0, data.shape[0], self.mbtsz):\n",
    "                mData = data[i:i + self.mbtsz]\n",
    "                ph_mean, nv_samples, nh_means = self.cd_k(mData)\n",
    "\n",
    "                self.mW = self.mW * self.mrate + (np.dot(mData.T, ph_mean) - np.dot(nv_samples.T, nh_means))\n",
    "                self.mvbias = self.mvbias * self.mrate + np.mean(mData - nv_samples, axis=0)\n",
    "                self.mhbias = self.mhbias * self.mrate + np.mean(ph_mean - nh_means, axis=0)\n",
    "                \n",
    "                prior1 = np.zeros((self.n_visible,self.n_hidden))\n",
    "                prior2 = np.zeros((self.n_visible,self.n_hidden))\n",
    "                prior3 = np.zeros((self.n_visible,self.n_hidden))\n",
    "                prior4 = np.zeros((self.n_visible,self.n_hidden))\n",
    "                for doc in range(mData.shape[0]):\n",
    "\n",
    "                    vk = mData[doc]\n",
    "                    Gj = np.zeros((self.n_visible,self.n_hidden))\n",
    "\n",
    "                    for i in range(0,self.n_visible):\n",
    "                        if vk[i] != 0:                 \n",
    "                            for j in range(0,self.n_hidden):\n",
    "                                Gj[i][j] = self._logistic(self.W[i][j]*vk[i]+self.hbias[j])\n",
    "                                if 1/(1+Gj[i][j]) == self.p_Aj_vk[i][j] or 1/(1+Gj[i][j]) == self.p_A_vk[i][j] or 1/(1+Gj[i][j]) == self.p_s_vk[i][j] or 1/(1+Gj[i][j]) == self.p_sj_vk[i][j]:\n",
    "                                    continue\n",
    "                                if self.p_Aj_vk[i][j] != 0:\n",
    "                                    prior1[i][j] += 2*Gj[i][j]*vk[i]/((1+Gj[i][j])**2*(1/(1+Gj[i][j])-self.p_Aj_vk[i][j]))\n",
    "\n",
    "                                #if 1/(1+Gj[i][j])-self.p_A_vk[i][j] != 0:\n",
    "                                if self.p_A_vk[i][j] != 0:\n",
    "                                    prior2[i][j] += 2*Gj[i][j]*vk[i]/((1+Gj[i][j])**2*(1/(1+Gj[i][j])-self.p_A_vk[i][j]))\n",
    "\n",
    "                                if self.p_s_vk[i][j] != 0:\n",
    "                                    prior3[i][j] += 2*Gj[i][j]*vk[i]/((1+Gj[i][j])**2*(1/(1+Gj[i][j])-self.p_s_vk[i][j]))\n",
    "\n",
    "                                if self.p_sj_vk[i][j] != 0:\n",
    "                                    prior4[i][j] += 2*Gj[i][j]*vk[i]/((1+Gj[i][j])**2*(1/(1+Gj[i][j])-self.p_sj_vk[i][j]))\n",
    "                \n",
    "                self.W += self.eta * self.mW - self.lambda1*prior1 - self.lambda2*prior2-self.lambda3*prior3 - self.lambda4*prior4\n",
    "                #self.W += self.eta * self.mW \n",
    "                self.vbias += self.eta * self.mvbias\n",
    "                self.hbias += self.eta * self.mhbias\n",
    "\n",
    "    def cd_k(self, data, k=1):\n",
    "        D = data.sum(axis=1)\n",
    "        ph_mean, ph_sample = self.sample_h(data, D)\n",
    "        chain_start = ph_sample\n",
    "\n",
    "        for step in range(k):\n",
    "            if step == 0:\n",
    "                nv_means, nv_samples, nh_means, nh_samples = self.gibbs_hvh(chain_start, D) \n",
    "            else:\n",
    "                nv_means, nv_samples, nh_means, nh_samples = self.gibbs_hvh(nh_samples, D)\n",
    "        return ph_mean, nv_samples, nh_means\n",
    "\n",
    "    def sample_h(self, v0_sample, D):\n",
    "        h1_mean = sigmoid(np.dot(v0_sample, self.W) + np.outer(D, self.hbias))\n",
    "        h1_sample = self.np_rng.binomial(size=h1_mean.shape, n=1, p=h1_mean)\n",
    "        return [h1_mean, h1_sample]\n",
    "\n",
    "    def sample_v(self, h0_sample, D):\n",
    "        x = np.dot(h0_sample, self.W.T)\n",
    "        x = np.clip( x, -500, 500 )\n",
    "        pre_soft = np.exp( x+ self.vbias)\n",
    "        pre_soft_sum = pre_soft.sum(axis=1).reshape((self.mbtsz, 1))\n",
    "        v1_mean = pre_soft/pre_soft_sum\n",
    "        v1_sample = np.zeros((self.mbtsz, v1_mean.shape[1]))\n",
    "        for i in range(self.mbtsz):\n",
    "            v1_sample[i] = self.np_rng.multinomial(size=1, n=D[i], pvals=v1_mean[i])\n",
    "        return [v1_mean, v1_sample]\n",
    "\n",
    "    def gibbs_hvh(self, h0_sample, D):\n",
    "        v1_mean, v1_sample = self.sample_v(h0_sample, D)\n",
    "        h1_mean, h1_sample = self.sample_h(v1_sample, D)\n",
    "        return [v1_mean, v1_sample, h1_mean, h1_sample]\n",
    "\n",
    "    def wordPredict(self, topic, voc):\n",
    "        vecTopics = np.zeros((topic, topic))\n",
    "        for i in range(len(vecTopics)):\n",
    "            vecTopics[i][i] = 1\n",
    "        for i, vecTopic in enumerate(vecTopics):\n",
    "            pre_soft = np.exp(np.dot(vecTopic, self.W.T) + self.vbias)\n",
    "            pre_soft_sum = pre_soft.sum().reshape((1, 1))\n",
    "            word_distribution = (pre_soft/pre_soft_sum).flatten()\n",
    "            tmpDict = {}\n",
    "            for j in range(len(voc)):\n",
    "                tmpDict[voc[j]] = word_distribution[j]\n",
    "            print 'topic', str(i), ':', vecTopic\n",
    "            k = 0\n",
    "            for word, prob in sorted(tmpDict.items(), key=lambda x:x[1], reverse=True):\n",
    "                if (k < 30):\n",
    "                    print word, str(prob)\n",
    "                    k = k+1\n",
    "            print '-'\n",
    "    def run_visible(self, data,t):\n",
    "        num_examples = data.shape[0]\n",
    "        hidden_states = np.ones((num_examples, self.n_hidden))\n",
    "        \n",
    "        hidden_activations = np.dot(data, self.W)+self.hbias        \n",
    "        hidden_probs = self._logistic(hidden_activations)\n",
    "        '''\n",
    "        for i in range(hidden_probs.shape[0]):\n",
    "            m= max(hidden_probs[i])\n",
    "            for j in range(hidden_probs.shape[1]):\n",
    "                if hidden_probs[i][j] == m:\n",
    "                    hidden_states[i][j] = 1\n",
    "                else:\n",
    "                    hidden_states[i][j] =0 \n",
    "        '''\n",
    "        threshold = t* np.ones((num_examples, self.n_hidden))\n",
    "        hidden_states[:,:] = hidden_probs > threshold\n",
    "        return hidden_states    \n",
    "\n",
    "    def _logistic(self, x):\n",
    "        x = np.clip( x, -500, 500 )\n",
    "        return 1.0 / (1 + np.exp(-x))  \n",
    "\n",
    "    def saveParams(self, filePath):\n",
    "        cPickle.dump({'W': self.W,\n",
    "                      'vbias': self.vbias,\n",
    "                      'hbias': self.hbias},\n",
    "                      open(filePath, 'w'))\n",
    "\n",
    "def inputData(filePath):\n",
    "    docs = []\n",
    "    voc = defaultdict(lambda: len(voc))\n",
    "    file = open(filePath, \"r\")\n",
    "    for line in file:\n",
    "        doc = line.rstrip().split()\n",
    "        for word in doc:\n",
    "            voc[word]\n",
    "        cnt = Counter(doc)\n",
    "        docs.append(cnt)\n",
    "    file.close()\n",
    "    docSize, vocSize = len(docs), len(voc)\n",
    "    v = np.zeros((docSize, vocSize))\n",
    "    for i in range(docSize):\n",
    "        for word, freq in docs[i].most_common():\n",
    "            wID = voc[word]\n",
    "            v[i][wID] = freq\n",
    "    return v, {v:k for k, v in voc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Total number of sentences: 179139\n",
      "Number of training objects:  15000\n",
      "Number of vocabulary dictionary:  8959\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "doc_len = [0 for x in range(0,52624)]\n",
    "doc_id = 0\n",
    "with open('test_rr.txt') as f:\n",
    "    content = f.readlines()\n",
    "dataset = []\n",
    "for line in content:\n",
    "    i, words = line.split('\\t')\n",
    "    i = int(i)\n",
    "    if doc_id == i:\n",
    "        doc_len[i] = doc_len[i]+1\n",
    "    else:\n",
    "        doc_id = i\n",
    "        doc_len[i]=1\n",
    "    dataset.append(words.strip())\n",
    "print 'Total number of sentences:' ,len(dataset)\n",
    "tf_vectorizer = CountVectorizer(max_df = 0.85,stop_words = 'english',max_features = 10000)\n",
    "tf = tf_vectorizer.fit_transform(dataset[0:15000])\n",
    "tf = tf.toarray()\n",
    "print 'Number of training objects: ', tf.shape[0]\n",
    "print 'Number of vocabulary dictionary: ', tf.shape[1]\n",
    "\n",
    "#vocab = tf_vectorizer.get_feature_names()\n",
    "vocab = tf_vectorizer.vocabulary_\n",
    "voc = defaultdict(lambda: len(voc))\n",
    "\n",
    "for k,v in vocab.items():\n",
    "    voc[v]=k\n",
    "docs = tf\n",
    "p_Aj_vk = np.loadtxt('p_Aj_vk')\n",
    "p_A_vk = np.loadtxt('p_A_vk' )\n",
    "p_s_vk = np.loadtxt('p_s_vk')\n",
    "p_sj_vk = np.loadtxt('p_sj_vk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "topic 0 : [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "good 0.71097929205\n",
      "wine 0.104821661652\n",
      "list 0.048427253918\n",
      "highly 0.04566918602\n",
      "recommended 0.0192548076766\n",
      "glass 0.0131384457555\n",
      "nice 0.0118113090717\n",
      "selection 0.00943310731536\n",
      "fantastic 0.00766146222216\n",
      "definitely 0.00560897239007\n",
      "think 0.0049289787984\n",
      "place 0.00465012417797\n",
      "restaurant 0.00397008985121\n",
      "come 0.00373744530931\n",
      "value 0.00346859292651\n",
      "interesting 0.00119184829197\n",
      "work 0.000404358402058\n",
      "decent 0.000149507075673\n",
      "extensive 0.000139197069685\n",
      "neighborhood 0.00013475337194\n",
      "service 7.6719369327e-05\n",
      "overall 5.93752168514e-05\n",
      "wonderful 4.22499330743e-05\n",
      "check 3.06694487708e-05\n",
      "bottle 2.64506710228e-05\n",
      "really 1.63641218341e-05\n",
      "return 1.55491663094e-05\n",
      "favorite 1.49703924821e-05\n",
      "best 1.4180010854e-05\n",
      "authentic 1.08945832641e-05\n",
      "-\n",
      "topic 1 : [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "excellent 0.4090902793\n",
      "amaze 0.327143959431\n",
      "restaurant 0.0776024913038\n",
      "place 0.0673710924421\n",
      "service 0.0518903079642\n",
      "terrible 0.0203829264775\n",
      "wonderful 0.012207437315\n",
      "fantastic 0.0108111242937\n",
      "dessert 0.00631376651266\n",
      "awesome 0.00539822830481\n",
      "awful 0.00345776243934\n",
      "worst 0.000895412049366\n",
      "best 0.000239198200611\n",
      "really 0.000222787035899\n",
      "far 0.000187930736514\n",
      "notch 0.000109913443193\n",
      "know 9.35990220511e-05\n",
      "think 8.27167198038e-05\n",
      "nyc 8.12425250931e-05\n",
      "miss 7.41024884437e-05\n",
      "love 7.30360679583e-05\n",
      "favorite 6.84166918263e-05\n",
      "better 6.49504896779e-05\n",
      "perfect 5.94359951358e-05\n",
      "pretty 5.33831302024e-05\n",
      "meal 5.17691481793e-05\n",
      "happen 5.06813721536e-05\n",
      "dish 4.83815064202e-05\n",
      "nice 4.34126856366e-05\n",
      "wrong 4.25778478901e-05\n",
      "-\n",
      "topic 2 : [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "place 0.0467662806086\n",
      "cake 0.015849301813\n",
      "tender 0.0142629341991\n",
      "sauce 0.0139584663304\n",
      "delicious 0.013606069856\n",
      "shrimp 0.0129598733475\n",
      "spicy 0.0129005154285\n",
      "rice 0.0103963454249\n",
      "mouth 0.0101877895641\n",
      "restaurant 0.0101228359141\n",
      "crab 0.0096020840957\n",
      "include 0.00934220613225\n",
      "flavorful 0.00896679433438\n",
      "mushroom 0.0087024216007\n",
      "grilled 0.008377379979\n",
      "appetizer 0.00836955502429\n",
      "good 0.00836210482467\n",
      "die 0.00834682812293\n",
      "salt 0.00824678644284\n",
      "dessert 0.00815082390362\n",
      "pork 0.00796872409164\n",
      "lobster 0.00780394664666\n",
      "cocktail 0.00753037256992\n",
      "tuna 0.00738776843697\n",
      "outstanding 0.00696060318374\n",
      "potatoe 0.0069339636807\n",
      "salmon 0.0065623169081\n",
      "entree 0.0062187614817\n",
      "green 0.00617833065349\n",
      "clam 0.00612862752144\n",
      "-\n",
      "topic 3 : [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "restaurant 0.457777822259\n",
      "place 0.101451628899\n",
      "favorite 0.0578800483628\n",
      "nyc 0.0496340767403\n",
      "avoid 0.039783787771\n",
      "know 0.0236695730734\n",
      "amazing 0.0189802691528\n",
      "miss 0.0185203118472\n",
      "fantastic 0.0119357548919\n",
      "simply 0.0096544372752\n",
      "definitely 0.00851223469296\n",
      "awesome 0.00785113113116\n",
      "cost 0.00758592096602\n",
      "glad 0.00592075966113\n",
      "fun 0.00540535580604\n",
      "pretty 0.00511791606157\n",
      "come 0.00362707662214\n",
      "clean 0.00357879090626\n",
      "neighborhood 0.00310415204013\n",
      "love 0.00268697988589\n",
      "best 0.0026271610388\n",
      "sure 0.00261323714964\n",
      "ny 0.00246787040647\n",
      "better 0.00236405536989\n",
      "really 0.00219543941236\n",
      "twice 0.00215906157526\n",
      "disappointed 0.00214996449254\n",
      "think 0.00179525947322\n",
      "away 0.00178522251927\n",
      "happen 0.00170106084651\n",
      "-\n",
      "topic 4 : [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "restaurant 0.349088396363\n",
      "place 0.253837819116\n",
      "know 0.076649026765\n",
      "fun 0.0677344124484\n",
      "fantastic 0.00923306941016\n",
      "definitely 0.00821255264048\n",
      "come 0.00613641193849\n",
      "awesome 0.00582305627523\n",
      "pretty 0.0056474265479\n",
      "miss 0.00522887672202\n",
      "sure 0.00373556608326\n",
      "think 0.0033606764109\n",
      "wrong 0.00319548533376\n",
      "clean 0.00312227184309\n",
      "love 0.00277861681187\n",
      "happen 0.00268920144643\n",
      "disappointed 0.0024912548453\n",
      "avoid 0.00246970002546\n",
      "best 0.00222828859426\n",
      "favorite 0.00209424872485\n",
      "nyc 0.00202075235004\n",
      "really 0.00199783259132\n",
      "wonderful 0.00194798876122\n",
      "yum 0.00183598513394\n",
      "amazing 0.00182718883289\n",
      "nice 0.00149412107965\n",
      "want 0.00148463343297\n",
      "perfect 0.00146459513854\n",
      "better 0.00136288246156\n",
      "right 0.001361217288\n",
      "-\n",
      "topic 5 : [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "restaurant 0.339394967481\n",
      "place 0.242165343945\n",
      "fun 0.0821148722693\n",
      "know 0.0775675690984\n",
      "fantastic 0.00930913837143\n",
      "definitely 0.008447448091\n",
      "awesome 0.00643022774007\n",
      "come 0.00610111331412\n",
      "avoid 0.00587730861973\n",
      "pretty 0.00557549146297\n",
      "miss 0.00485899836226\n",
      "sure 0.0036815097467\n",
      "clean 0.00340678911224\n",
      "think 0.00335681476606\n",
      "wrong 0.00315847822036\n",
      "happen 0.00299533795692\n",
      "love 0.00285464699814\n",
      "cost 0.00279927052017\n",
      "best 0.00219683277076\n",
      "really 0.00209803333721\n",
      "disappointed 0.0020440592341\n",
      "wonderful 0.00203211423832\n",
      "nyc 0.00196121180318\n",
      "favorite 0.00189733440317\n",
      "amazing 0.00186858178702\n",
      "yum 0.00181502974918\n",
      "nice 0.00150799241089\n",
      "want 0.00149771144022\n",
      "perfect 0.00146579931871\n",
      "right 0.0013760782584\n",
      "-\n",
      "topic 6 : [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "staff 0.161918659276\n",
      "service 0.122957385449\n",
      "attentive 0.048037203256\n",
      "help 0.0262248126114\n",
      "excellent 0.0201798332724\n",
      "good 0.0146082517686\n",
      "seat 0.0133909488021\n",
      "bad 0.0130260028082\n",
      "waitres 0.012627276493\n",
      "professional 0.0125674035165\n",
      "really 0.0112819245586\n",
      "knowledgeable 0.0108348050187\n",
      "server 0.0102599179468\n",
      "wait 0.00961886771493\n",
      "accomodate 0.00927268910874\n",
      "friendly 0.00881977637774\n",
      "slow 0.00840463020608\n",
      "rush 0.00808339378123\n",
      "polite 0.00775382078141\n",
      "greet 0.00752838496109\n",
      "nice 0.00748390795942\n",
      "waiter 0.00731233752683\n",
      "ful 0.00711476545433\n",
      "say 0.0068998772214\n",
      "cold 0.00646749759776\n",
      "extremely 0.00525833035847\n",
      "review 0.00519946107262\n",
      "time 0.00507882912184\n",
      "surprise 0.00488661525758\n",
      "horrible 0.00480125929865\n",
      "-\n",
      "topic 7 : [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "price 0.124855196419\n",
      "definitely 0.0785647351461\n",
      "reasonable 0.0623357151671\n",
      "worth 0.0535953956974\n",
      "bad 0.0291596179932\n",
      "come 0.0270850224455\n",
      "meal 0.0253953608588\n",
      "good 0.0232366295473\n",
      "wrong 0.0221212697749\n",
      "beat 0.0183347823687\n",
      "disappoint 0.0161892418493\n",
      "think 0.0129095940597\n",
      "best 0.0127033985936\n",
      "way 0.0122929963735\n",
      "wait 0.0122262411774\n",
      "time 0.0120501157912\n",
      "dessert 0.0119508686152\n",
      "nyc 0.0107851629208\n",
      "value 0.010394770041\n",
      "bravo 0.00905307836734\n",
      "experience 0.00877487822376\n",
      "check 0.00849673439053\n",
      "visit 0.00837221608519\n",
      "charge 0.00822004167225\n",
      "soon 0.00820052721745\n",
      "return 0.00805349205579\n",
      "reasonably 0.00723840500263\n",
      "free 0.00650350543642\n",
      "outstanding 0.00632848966682\n",
      "entree 0.00621760962317\n",
      "-\n",
      "topic 8 : [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "place 0.0378863420121\n",
      "music 0.0289011624084\n",
      "ambience 0.025257199446\n",
      "room 0.023934125411\n",
      "nice 0.0191820635509\n",
      "loud 0.0168521398649\n",
      "portion 0.0117059148627\n",
      "hip 0.0115618764578\n",
      "try 0.0107191535546\n",
      "look 0.0103299000067\n",
      "village 0.010145531637\n",
      "definitely 0.0088123198333\n",
      "atmosphere 0.00829059870955\n",
      "romantic 0.00816141188681\n",
      "small 0.0081336389272\n",
      "space 0.00810208975083\n",
      "anythe 0.00779528736573\n",
      "cozy 0.00777897386722\n",
      "set 0.00771254832662\n",
      "come 0.00767328626049\n",
      "love 0.00686097979371\n",
      "restaurant 0.00672875006269\n",
      "area 0.00670164920416\n",
      "east 0.00622422710048\n",
      "casual 0.00613816172589\n",
      "worth 0.00609905355313\n",
      "bit 0.00604494002692\n",
      "time 0.00584746201582\n",
      "square 0.00579032357316\n",
      "noisy 0.00553335598033\n",
      "-\n",
      "topic 9 : [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "wait 0.0401320215453\n",
      "reservation 0.0337768540971\n",
      "dinner 0.0306709903805\n",
      "friend 0.0270534843355\n",
      "experience 0.018345389316\n",
      "time 0.0183143881885\n",
      "tell 0.0177433794871\n",
      "late 0.0157317629239\n",
      "hour 0.0140659956075\n",
      "night 0.0115151749588\n",
      "long 0.0103580851885\n",
      "sure 0.00940794637265\n",
      "table 0.00922755563871\n",
      "come 0.009031284793\n",
      "bring 0.00857009421561\n",
      "week 0.00832267812873\n",
      "love 0.00810599603784\n",
      "saturday 0.00810457146368\n",
      "worth 0.00749895556015\n",
      "try 0.00698375987597\n",
      "hell 0.00694252978127\n",
      "party 0.00650253897224\n",
      "lupa 0.00641157952546\n",
      "restaurant 0.00619404108035\n",
      "return 0.00600208054593\n",
      "year 0.00581308164215\n",
      "past 0.00575737094369\n",
      "away 0.00560326562564\n",
      "lunch 0.00550415354821\n",
      "friday 0.00540538148015\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "topic = 10\n",
    "rbm = RBM( n_visible=len(docs[0]), \n",
    "           n_hidden=topic, \n",
    "           mbtsz=50,\n",
    "           epochs=10,\n",
    "           eta=0.1,\n",
    "           mrate=0.8,\n",
    "           np_rng=np.random.RandomState(1234),\n",
    "           lambda1 = 0.04, lambda2 = 0.01, lambda3 = 0.01,lambda4 = 0.01, \n",
    "           p_A_vk = p_A_vk,p_s_vk = p_s_vk,p_Aj_vk= p_Aj_vk,p_sj_vk = p_sj_vk)\n",
    "\n",
    "rbm.train(docs[0:15000])\n",
    "rbm.wordPredict(topic, voc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730827067669\n",
      "0.376379477251\n",
      "0.496869009585\n",
      "0.533302497687\n",
      "0.623580313683\n",
      "0.574918972825\n",
      "0.360275689223\n",
      "0.494836488812\n",
      "0.416968817984\n"
     ]
    }
   ],
   "source": [
    "label = np.loadtxt('labels')[0:15000]\n",
    "result =rbm.run_visible(docs[0:15000],0.99)\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "\n",
    "print(precision_score(label[:,0],result[:,2]))\n",
    "print(recall_score(label[:,0],result[:,2]))\n",
    "print(f1_score(label[:,0],result[:,2]))\n",
    "\n",
    "print(precision_score(label[:,1],result[:,6]))\n",
    "print(recall_score(label[:,1],result[:,6]))\n",
    "print(f1_score(label[:,1],result[:,6]))\n",
    "\n",
    "print(precision_score(label[:,2],result[:,8]))\n",
    "print(recall_score(label[:,2],result[:,8]))\n",
    "print(f1_score(label[:,2],result[:,8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('rbm.txt',result,fmt = '%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "topic 0 : [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "food 0.773813706156\n",
      "delicious 0.047049838745\n",
      "highly 0.0430316140648\n",
      "fantastic 0.0300558027493\n",
      "best 0.0188862401376\n",
      "fun 0.0148665177754\n",
      "recommended 0.0142244455954\n",
      "wonderful 0.013892720645\n",
      "absolutely 0.00815230214643\n",
      "think 0.00722398996762\n",
      "ok 0.00537374174872\n",
      "italian 0.00417631403085\n",
      "restaurant 0.00348971054679\n",
      "authentic 0.00348147159341\n",
      "amazing 0.00214432427038\n",
      "average 0.0020347908663\n",
      "definitely 0.00135380623463\n",
      "terrible 0.00120227697363\n",
      "prepared 0.00106061093574\n",
      "fresh 0.000915317268552\n",
      "tasty 0.000850340334477\n",
      "expect 0.000821537833215\n",
      "awesome 0.000726476283768\n",
      "excellent 0.00054442939722\n",
      "amaze 0.000272486767054\n",
      "importantly 0.000162108850914\n",
      "mediocre 4.47541312157e-05\n",
      "indian 3.99113017044e-05\n",
      "outstanding 3.44555571429e-05\n",
      "horrible 1.27668265281e-05\n",
      "-\n",
      "topic 1 : [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "excellent 0.54577853977\n",
      "food 0.265375651167\n",
      "restaurant 0.180973856772\n",
      "service 0.0078663499178\n",
      "delicious 3.79513530347e-06\n",
      "fresh 1.99423474746e-07\n",
      "definitely 3.25353155952e-08\n",
      "think 2.22046938387e-08\n",
      "dessert 2.21609129024e-08\n",
      "know 1.96737178439e-08\n",
      "wonderful 1.54576382819e-08\n",
      "fun 1.39389859426e-08\n",
      "make 1.24267572587e-08\n",
      "new 1.18151404611e-08\n",
      "pretty 1.17313691167e-08\n",
      "want 1.03858099467e-08\n",
      "better 9.63881950738e-09\n",
      "wine 9.39905247301e-09\n",
      "small 9.3766306578e-09\n",
      "special 9.01762788788e-09\n",
      "fantastic 8.42203515604e-09\n",
      "perfect 7.36514894786e-09\n",
      "italian 7.35502753504e-09\n",
      "meal 6.96966942307e-09\n",
      "atmosphere 6.89842299885e-09\n",
      "table 6.89023692174e-09\n",
      "fish 6.75116870725e-09\n",
      "really 6.49853376673e-09\n",
      "terrible 6.36292207489e-09\n",
      "miss 6.33527398052e-09\n",
      "-\n",
      "topic 2 : [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "favorite 0.376137703652\n",
      "restaurant 0.217478817094\n",
      "nyc 0.053614862457\n",
      "far 0.0453277792895\n",
      "better 0.0289725189391\n",
      "know 0.0273229623223\n",
      "pretty 0.0219612461818\n",
      "definitely 0.0182506336683\n",
      "overrated 0.0180951093482\n",
      "ny 0.0175656640971\n",
      "indian 0.0166365961782\n",
      "surprise 0.01268677562\n",
      "disappointed 0.0113819241351\n",
      "brooklyn 0.0101109244921\n",
      "come 0.0094976048001\n",
      "sure 0.00666912177856\n",
      "miss 0.0049678906975\n",
      "fun 0.00469398427399\n",
      "begin 0.00430122880488\n",
      "expect 0.00367736677729\n",
      "happen 0.00353997369846\n",
      "neighborhood 0.00335913465459\n",
      "dumpling 0.00299301031181\n",
      "pleasant 0.00231445996411\n",
      "danube 0.00227722027286\n",
      "fantastic 0.00186485991165\n",
      "sorry 0.00167111782751\n",
      "rare 0.00156612855436\n",
      "avoid 0.00145010353091\n",
      "wrong 0.00141190550045\n",
      "-\n",
      "topic 3 : [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "restaurant 0.629683163541\n",
      "food 0.352000621005\n",
      "excellent 0.0183079271263\n",
      "delicious 3.79002888357e-06\n",
      "fresh 2.81539460881e-07\n",
      "definitely 7.74006616059e-08\n",
      "know 5.45156043402e-08\n",
      "think 5.16012445715e-08\n",
      "dessert 4.57795039353e-08\n",
      "come 4.13075442649e-08\n",
      "fun 3.77462644695e-08\n",
      "wonderful 3.14042541351e-08\n",
      "make 3.08142211424e-08\n",
      "new 3.04996494525e-08\n",
      "pretty 2.94551929538e-08\n",
      "fantastic 2.84839448044e-08\n",
      "want 2.77052448172e-08\n",
      "better 2.43629547282e-08\n",
      "special 2.3753964166e-08\n",
      "small 2.33748273413e-08\n",
      "wine 2.31898562497e-08\n",
      "waiter 2.01264337224e-08\n",
      "italian 1.89351425197e-08\n",
      "table 1.89346909148e-08\n",
      "perfect 1.81635456075e-08\n",
      "meal 1.77017407702e-08\n",
      "atmosphere 1.75817473624e-08\n",
      "sure 1.73985934517e-08\n",
      "fish 1.7393615961e-08\n",
      "average 1.6603633587e-08\n",
      "-\n",
      "topic 4 : [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "restaurant 0.62966891106\n",
      "food 0.352013976533\n",
      "excellent 0.0183082357656\n",
      "delicious 4.36169192025e-06\n",
      "fresh 2.89735963033e-07\n",
      "definitely 7.60274860553e-08\n",
      "know 5.42709768006e-08\n",
      "think 5.20901348571e-08\n",
      "dessert 4.58018158239e-08\n",
      "come 4.14356178416e-08\n",
      "fun 3.74920288642e-08\n",
      "wonderful 3.16391362672e-08\n",
      "make 3.09978454989e-08\n",
      "new 3.0632576129e-08\n",
      "pretty 2.94815502931e-08\n",
      "fantastic 2.86654262175e-08\n",
      "want 2.77832349216e-08\n",
      "better 2.44114668144e-08\n",
      "special 2.37302308816e-08\n",
      "small 2.34209743462e-08\n",
      "wine 2.32266525874e-08\n",
      "waiter 2.01355381531e-08\n",
      "italian 1.89779012565e-08\n",
      "table 1.89101587676e-08\n",
      "perfect 1.82073113594e-08\n",
      "meal 1.77165797696e-08\n",
      "atmosphere 1.753672237e-08\n",
      "sure 1.74885185687e-08\n",
      "fish 1.74581878642e-08\n",
      "average 1.66663428848e-08\n",
      "-\n",
      "topic 5 : [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "restaurant 0.629696718464\n",
      "food 0.351988103409\n",
      "excellent 0.0183071079303\n",
      "delicious 3.58195457372e-06\n",
      "fresh 2.79179735384e-07\n",
      "definitely 7.61087840477e-08\n",
      "know 5.43280206543e-08\n",
      "think 5.16646363218e-08\n",
      "dessert 4.55361614447e-08\n",
      "come 4.14258414105e-08\n",
      "fun 3.75709933055e-08\n",
      "wonderful 3.1328235844e-08\n",
      "make 3.07810561137e-08\n",
      "new 3.04706230016e-08\n",
      "pretty 2.94046496965e-08\n",
      "fantastic 2.83741488176e-08\n",
      "want 2.77044772907e-08\n",
      "better 2.43998663193e-08\n",
      "special 2.37061978064e-08\n",
      "small 2.33976510024e-08\n",
      "wine 2.31621803182e-08\n",
      "waiter 2.00924142522e-08\n",
      "italian 1.88860295954e-08\n",
      "table 1.88563925887e-08\n",
      "perfect 1.81449956442e-08\n",
      "meal 1.76583187729e-08\n",
      "sure 1.73983042158e-08\n",
      "atmosphere 1.73978682622e-08\n",
      "fish 1.73538310241e-08\n",
      "average 1.6579403716e-08\n",
      "-\n",
      "topic 6 : [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "worth 0.0633042318215\n",
      "price 0.0578452778574\n",
      "dine 0.0232856936578\n",
      "experience 0.0231970553242\n",
      "dessert 0.0220567079243\n",
      "definitely 0.0153806533121\n",
      "trip 0.0136424780006\n",
      "nyc 0.0134186661384\n",
      "room 0.0120608942555\n",
      "decor 0.00906299225327\n",
      "meal 0.00781388822517\n",
      "better 0.00776053494231\n",
      "worst 0.00766098154441\n",
      "service 0.0074965670093\n",
      "intimate 0.00734090952698\n",
      "mean 0.00722216610427\n",
      "best 0.00710060269908\n",
      "music 0.0069069977411\n",
      "think 0.00689064860044\n",
      "food 0.00651390671488\n",
      "romantic 0.00606219675498\n",
      "come 0.0058213550933\n",
      "loud 0.00579601861437\n",
      "menu 0.00562152923342\n",
      "reasonable 0.0053550099137\n",
      "eat 0.00513971594656\n",
      "decent 0.0051081542438\n",
      "area 0.00479600974489\n",
      "nice 0.00474238779203\n",
      "atmosphere 0.0045708957646\n",
      "-\n",
      "topic 7 : [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "service 0.107029237277\n",
      "staff 0.0500608132894\n",
      "friendly 0.0361441858582\n",
      "bad 0.0342166390806\n",
      "attentive 0.0323598384104\n",
      "help 0.0275144305943\n",
      "ful 0.0163098492138\n",
      "accomodate 0.0149607679232\n",
      "bartender 0.0136686988832\n",
      "waiter 0.0122189856256\n",
      "extremely 0.010670171013\n",
      "food 0.0105851772274\n",
      "server 0.0100794554584\n",
      "polite 0.00894958052326\n",
      "impeccable 0.00894805620896\n",
      "order 0.00862134284275\n",
      "somewhat 0.00835479855675\n",
      "nice 0.00807439941805\n",
      "attitude 0.00633625871052\n",
      "excellent 0.00630444045512\n",
      "ruin 0.00593261678942\n",
      "review 0.00591402190219\n",
      "wait 0.00586451773938\n",
      "waitres 0.00506211683641\n",
      "know 0.00499251924161\n",
      "professional 0.0048404147111\n",
      "quick 0.00482066649743\n",
      "definitely 0.0045936960297\n",
      "rude 0.00454751688618\n",
      "customer 0.00430146691768\n",
      "-\n",
      "topic 8 : [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "reservation 0.0429180525021\n",
      "wait 0.0267181975601\n",
      "tell 0.0259041212131\n",
      "table 0.024140321589\n",
      "know 0.022261188983\n",
      "time 0.0205524475165\n",
      "dinner 0.0177173842941\n",
      "lunch 0.0119845458177\n",
      "friend 0.0117649799097\n",
      "love 0.0115387289809\n",
      "think 0.0111949313971\n",
      "group 0.0108968049957\n",
      "late 0.0096986106112\n",
      "serve 0.00940984857793\n",
      "saturday 0.00922411934808\n",
      "open 0.00871312598683\n",
      "seat 0.00826084476495\n",
      "left 0.00779254966976\n",
      "arrive 0.00740497751068\n",
      "experience 0.00707306624111\n",
      "line 0.00701601009628\n",
      "weekend 0.00666168065886\n",
      "hour 0.00653516653862\n",
      "water 0.0062815157928\n",
      "week 0.00624780365345\n",
      "sit 0.00603126599248\n",
      "dont 0.00599773015022\n",
      "ask 0.0059199037388\n",
      "staff 0.00575876068845\n",
      "night 0.00545675535519\n",
      "-\n",
      "topic 9 : [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "sauce 0.0780636502781\n",
      "pork 0.0172528338343\n",
      "salad 0.0132598748528\n",
      "flavor 0.0129259756718\n",
      "dessert 0.0107836332354\n",
      "outstanding 0.0105843568059\n",
      "duck 0.0103716204283\n",
      "tender 0.0100944272514\n",
      "meat 0.00971567066151\n",
      "delicious 0.00920047869347\n",
      "appetizer 0.00837599316887\n",
      "try 0.00823030512239\n",
      "like 0.00719947378064\n",
      "cheese 0.00714390286914\n",
      "bean 0.00711909312536\n",
      "grilled 0.00598517999314\n",
      "spinach 0.0054643667925\n",
      "stick 0.00541595822907\n",
      "rare 0.00535718080946\n",
      "entree 0.0053465031308\n",
      "filet 0.00532021887218\n",
      "dish 0.00523978096316\n",
      "pepper 0.00488122964006\n",
      "tuna 0.00486539936784\n",
      "excellent 0.00480997483744\n",
      "small 0.00472254566148\n",
      "amaze 0.00471237943773\n",
      "chicken 0.004660721478\n",
      "clam 0.00451285284954\n",
      "tomato 0.0044760764272\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "#try different parameters for better accuracy\n",
    "\n",
    "rbm = RBM( n_visible=len(docs[0]), \n",
    "           n_hidden=topic, \n",
    "           mbtsz=50,\n",
    "           epochs=10,\n",
    "           eta=0.1,\n",
    "           mrate=0.8,\n",
    "           np_rng=np.random.RandomState(1234),\n",
    "           lambda1 = 0.01, lambda2 = 0.05, lambda3 = 0.01,lambda4 = 0.01, \n",
    "           p_A_vk = p_A_vk,p_s_vk = p_s_vk,p_Aj_vk= p_Aj_vk,p_sj_vk = p_sj_vk)\n",
    "\n",
    "rbm.train(docs[0:15000])\n",
    "rbm.wordPredict(topic, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.749122396443\n",
      "0.619748305905\n",
      "0.678321678322\n",
      "0.319858712716\n",
      "0.881557598702\n",
      "0.469402447804\n",
      "0.158092553441\n",
      "0.57917383821\n",
      "0.248385310943\n"
     ]
    }
   ],
   "source": [
    "label = np.loadtxt('labels')[0:15000]\n",
    "result =rbm.run_visible(docs[0:15000],0)\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "print(precision_score(label[:,0],result[:,6]))\n",
    "print(recall_score(label[:,0],result[:,6]))\n",
    "print(f1_score(label[:,0],result[:,6]))\n",
    "\n",
    "print(precision_score(label[:,1],result[:,7]))\n",
    "print(recall_score(label[:,1],result[:,7]))\n",
    "print(f1_score(label[:,1],result[:,7]))\n",
    "print(precision_score(label[:,2],result[:,8]))\n",
    "print(recall_score(label[:,2],result[:,8]))\n",
    "print(f1_score(label[:,2],result[:,8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normal RBM (without priors)\n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import cPickle\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    x = np.clip( x, -500, 500 )\n",
    "\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "class RBM(object):\n",
    "\n",
    "    def __init__(self, n_visible, n_hidden, mbtsz, epochs, eta, mrate, np_rng, weightinit=0.001,\\\n",
    "               lambda1 = 1, lambda2 = 1, lambda3 = 1,lambda4 = 1, \\\n",
    "               p_A_vk = None,p_s_vk = None,p_Aj_vk= None,p_sj_vk = None):\n",
    "        \"\"\"\n",
    "        CD-k training of RBM with SGD + Momentum.\n",
    "        @param n_visible:   num of lexicon\n",
    "        @param n_hidden:    num of latent topics\n",
    "        @param epochs:      training epochs\n",
    "        @param eta:         learning rate\n",
    "        @param mrate:       momentum rate\n",
    "        @param mbtsz:       mini-batch size\n",
    "        @param np_rng:      instances of RandomState\n",
    "        @param weightinit:  scaling of random weight initialization\n",
    "        \"\"\"\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "        self.mbtsz = mbtsz\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.mrate = mrate\n",
    "        self.np_rng = np_rng\n",
    "        self.W = weightinit * np_rng.randn(n_visible, n_hidden)\n",
    "        self.vbias = weightinit * np_rng.randn(n_visible)\n",
    "        self.hbias = np.zeros((n_hidden))\n",
    "        # for momentum\n",
    "        self.mW = np.zeros((n_visible, n_hidden))\n",
    "        self.mvbias = np.zeros((n_visible))\n",
    "        self.mhbias = np.zeros((n_hidden))\n",
    "\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.lambda3 = lambda3\n",
    "        self.lambda4 = lambda4\n",
    "        self.p_A_vk = p_A_vk\n",
    "        self.p_s_vk = p_s_vk\n",
    "        self.p_Aj_vk = p_Aj_vk\n",
    "        self.p_sj_vk = p_sj_vk\n",
    "    def train(self, data):\n",
    "        for epoch in range(self.epochs):\n",
    "            print(epoch)\n",
    "            #self.np_rng.shuffle(data)\n",
    "            for i in range(0, data.shape[0], self.mbtsz):\n",
    "                mData = data[i:i + self.mbtsz]\n",
    "                ph_mean, nv_samples, nh_means = self.cd_k(mData)\n",
    "\n",
    "                self.mW = self.mW * self.mrate + (np.dot(mData.T, ph_mean) - np.dot(nv_samples.T, nh_means))\n",
    "                self.mvbias = self.mvbias * self.mrate + np.mean(mData - nv_samples, axis=0)\n",
    "                self.mhbias = self.mhbias * self.mrate + np.mean(ph_mean - nh_means, axis=0)\n",
    "                '''\n",
    "                prior1 = np.zeros((self.n_visible,self.n_hidden))\n",
    "                prior2 = np.zeros((self.n_visible,self.n_hidden))\n",
    "                prior3 = np.zeros((self.n_visible,self.n_hidden))\n",
    "                prior4 = np.zeros((self.n_visible,self.n_hidden))\n",
    "                for doc in range(mData.shape[0]):\n",
    "\n",
    "                    vk = mData[doc]\n",
    "                    Gj = np.zeros((self.n_visible,self.n_hidden))\n",
    "\n",
    "                    for i in range(0,self.n_visible):\n",
    "                        if vk[i] != 0:                 \n",
    "                            for j in range(0,self.n_hidden):\n",
    "                                Gj[i][j] = self._logistic(self.W[i][j]*vk[i]+self.hbias[j])\n",
    "                                if 1/(1+Gj[i][j]) == self.p_Aj_vk[i][j] or 1/(1+Gj[i][j]) == self.p_A_vk[i][j] or 1/(1+Gj[i][j]) == self.p_s_vk[i][j] or 1/(1+Gj[i][j]) == self.p_sj_vk[i][j]:\n",
    "                                    continue\n",
    "                                if self.p_Aj_vk[i][j] != 0:\n",
    "                                    prior1[i][j] += 2*Gj[i][j]*vk[i]/((1+Gj[i][j])**2*(1/(1+Gj[i][j])-self.p_Aj_vk[i][j]))\n",
    "\n",
    "                                #if 1/(1+Gj[i][j])-self.p_A_vk[i][j] != 0:\n",
    "                                if self.p_A_vk[i][j] != 0:\n",
    "                                    prior2[i][j] += 2*Gj[i][j]*vk[i]/((1+Gj[i][j])**2*(1/(1+Gj[i][j])-self.p_A_vk[i][j]))\n",
    "\n",
    "                                if self.p_s_vk[i][j] != 0:\n",
    "                                    prior3[i][j] += 2*Gj[i][j]*vk[i]/((1+Gj[i][j])**2*(1/(1+Gj[i][j])-self.p_s_vk[i][j]))\n",
    "\n",
    "                                if self.p_sj_vk[i][j] != 0:\n",
    "                                    prior4[i][j] += 2*Gj[i][j]*vk[i]/((1+Gj[i][j])**2*(1/(1+Gj[i][j])-self.p_sj_vk[i][j]))\n",
    "                '''\n",
    "                #self.W += self.eta * self.mW - self.lambda1*prior1 - self.lambda2*prior2-self.lambda3*prior3 - self.lambda4*prior4\n",
    "                self.W += self.eta * self.mW \n",
    "                self.vbias += self.eta * self.mvbias\n",
    "                self.hbias += self.eta * self.mhbias\n",
    "\n",
    "    def cd_k(self, data, k=1):\n",
    "        D = data.sum(axis=1)\n",
    "        ph_mean, ph_sample = self.sample_h(data, D)\n",
    "        chain_start = ph_sample\n",
    "\n",
    "        for step in range(k):\n",
    "            if step == 0:\n",
    "                nv_means, nv_samples, nh_means, nh_samples = self.gibbs_hvh(chain_start, D) \n",
    "            else:\n",
    "                nv_means, nv_samples, nh_means, nh_samples = self.gibbs_hvh(nh_samples, D)\n",
    "        return ph_mean, nv_samples, nh_means\n",
    "\n",
    "    def sample_h(self, v0_sample, D):\n",
    "        h1_mean = sigmoid(np.dot(v0_sample, self.W) + np.outer(D, self.hbias))\n",
    "        h1_sample = self.np_rng.binomial(size=h1_mean.shape, n=1, p=h1_mean)\n",
    "        return [h1_mean, h1_sample]\n",
    "\n",
    "    def sample_v(self, h0_sample, D):\n",
    "        x = np.dot(h0_sample, self.W.T)\n",
    "        x = np.clip( x, -500, 500 )\n",
    "        pre_soft = np.exp( x+ self.vbias)\n",
    "        pre_soft_sum = pre_soft.sum(axis=1).reshape((self.mbtsz, 1))\n",
    "        v1_mean = pre_soft/pre_soft_sum\n",
    "        v1_sample = np.zeros((self.mbtsz, v1_mean.shape[1]))\n",
    "        for i in range(self.mbtsz):\n",
    "            v1_sample[i] = self.np_rng.multinomial(size=1, n=D[i], pvals=v1_mean[i])\n",
    "        return [v1_mean, v1_sample]\n",
    "\n",
    "    def gibbs_hvh(self, h0_sample, D):\n",
    "        v1_mean, v1_sample = self.sample_v(h0_sample, D)\n",
    "        h1_mean, h1_sample = self.sample_h(v1_sample, D)\n",
    "        return [v1_mean, v1_sample, h1_mean, h1_sample]\n",
    "\n",
    "    def wordPredict(self, topic, voc):\n",
    "        vecTopics = np.zeros((topic, topic))\n",
    "        for i in range(len(vecTopics)):\n",
    "            vecTopics[i][i] = 1\n",
    "        for i, vecTopic in enumerate(vecTopics):\n",
    "            pre_soft = np.exp(np.dot(vecTopic, self.W.T) + self.vbias)\n",
    "            pre_soft_sum = pre_soft.sum().reshape((1, 1))\n",
    "            word_distribution = (pre_soft/pre_soft_sum).flatten()\n",
    "            tmpDict = {}\n",
    "            for j in range(len(voc)):\n",
    "                tmpDict[voc[j]] = word_distribution[j]\n",
    "            print 'topic', str(i), ':', vecTopic\n",
    "            k = 0\n",
    "            for word, prob in sorted(tmpDict.items(), key=lambda x:x[1], reverse=True):\n",
    "                if (k < 30):\n",
    "                    print word, str(prob)\n",
    "                    k = k+1\n",
    "            print '-'\n",
    "    def run_visible(self, data,t):\n",
    "        num_examples = data.shape[0]\n",
    "        hidden_states = np.ones((num_examples, self.n_hidden))\n",
    "        \n",
    "        hidden_activations = np.dot(data, self.W)+self.hbias        \n",
    "        hidden_probs = self._logistic(hidden_activations)\n",
    "        for i in range(hidden_probs.shape[0]):\n",
    "            m= max(hidden_probs[i])\n",
    "            for j in range(hidden_probs.shape[1]):\n",
    "                if hidden_probs[i][j] == m:\n",
    "                    hidden_states[i][j] = 1\n",
    "                else:\n",
    "                    hidden_states[i][j] =0        \n",
    "        #threshold = t* np.ones((num_examples, self.n_hidden))\n",
    "        #hidden_states[:,:] = hidden_probs > threshold\n",
    "        return hidden_states    \n",
    "\n",
    "    def _logistic(self, x):\n",
    "        x = np.clip( x, -500, 500 )\n",
    "        return 1.0 / (1 + np.exp(-x))  \n",
    "\n",
    "    def saveParams(self, filePath):\n",
    "        cPickle.dump({'W': self.W,\n",
    "                      'vbias': self.vbias,\n",
    "                      'hbias': self.hbias},\n",
    "                      open(filePath, 'w'))\n",
    "\n",
    "def inputData(filePath):\n",
    "    docs = []\n",
    "    voc = defaultdict(lambda: len(voc))\n",
    "    file = open(filePath, \"r\")\n",
    "    for line in file:\n",
    "        doc = line.rstrip().split()\n",
    "        for word in doc:\n",
    "            voc[word]\n",
    "        cnt = Counter(doc)\n",
    "        docs.append(cnt)\n",
    "    file.close()\n",
    "    docSize, vocSize = len(docs), len(voc)\n",
    "    v = np.zeros((docSize, vocSize))\n",
    "    for i in range(docSize):\n",
    "        for word, freq in docs[i].most_common():\n",
    "            wID = voc[word]\n",
    "            v[i][wID] = freq\n",
    "    return v, {v:k for k, v in voc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "topic 0 : [ 1.  0.  0.  0.  0.  0.]\n",
      "good 0.139966849224\n",
      "experience 0.0779364736623\n",
      "great 0.0555212040315\n",
      "price 0.0373843252411\n",
      "dessert 0.035528114858\n",
      "meal 0.026523199009\n",
      "overall 0.0263259125905\n",
      "bad 0.0217774662859\n",
      "excellent 0.0199434301266\n",
      "reasonable 0.0174974458685\n",
      "really 0.0174325033738\n",
      "beat 0.0146590172928\n",
      "dine 0.0126927158176\n",
      "better 0.0126311046985\n",
      "nyc 0.010261263577\n",
      "best 0.00977728540716\n",
      "value 0.00917016001272\n",
      "taste 0.00895001945997\n",
      "everythe 0.00876463563418\n",
      "stay 0.00662260047327\n",
      "miss 0.00606548004447\n",
      "say 0.00573404857636\n",
      "definitely 0.00573302544249\n",
      "love 0.0053613758348\n",
      "away 0.00532709636927\n",
      "pizza 0.00500847198244\n",
      "coffee 0.00496461295363\n",
      "fresh 0.00435417528327\n",
      "appetizer 0.00425361075954\n",
      "deal 0.00415288968704\n",
      "-\n",
      "topic 1 : [ 0.  1.  0.  0.  0.  0.]\n",
      "shrimp 0.0217155005559\n",
      "delicious 0.0193180794588\n",
      "appetizer 0.0159969589477\n",
      "steak 0.0129906417659\n",
      "mouth 0.0122168552184\n",
      "melt 0.0106350006175\n",
      "potatoe 0.010469052448\n",
      "cake 0.00998491117504\n",
      "mushroom 0.00976518161897\n",
      "bas 0.00950140600773\n",
      "salt 0.00946982671623\n",
      "try 0.00942133274905\n",
      "flavor 0.00925341768301\n",
      "sauce 0.00859287629111\n",
      "tender 0.00846909317304\n",
      "outstanding 0.00844097393765\n",
      "pepper 0.00839976008403\n",
      "salad 0.00836515218793\n",
      "fish 0.00759560778849\n",
      "chocolate 0.00726901646211\n",
      "entree 0.0069249982035\n",
      "roll 0.00680340453468\n",
      "crab 0.00678171351911\n",
      "bean 0.00674636663519\n",
      "mignon 0.00668251527647\n",
      "cream 0.006472563331\n",
      "noodle 0.00601986907084\n",
      "tomato 0.00582868818546\n",
      "dessert 0.00573467516167\n",
      "crust 0.00566953916604\n",
      "-\n",
      "topic 2 : [ 0.  0.  1.  0.  0.  0.]\n",
      "decor 0.0776668948905\n",
      "say 0.0328907545744\n",
      "romantic 0.0295393558131\n",
      "amaze 0.0173564076679\n",
      "thank 0.0159060341743\n",
      "delicious 0.0156012801593\n",
      "space 0.0140857602615\n",
      "love 0.0125108804824\n",
      "ambiance 0.0117939813433\n",
      "large 0.0117529657241\n",
      "best 0.011359886754\n",
      "portion 0.0112279781111\n",
      "enjoy 0.0106122934059\n",
      "beautiful 0.0102696223674\n",
      "believe 0.00977178163522\n",
      "great 0.00941227228679\n",
      "cute 0.00837568734323\n",
      "word 0.00825662371618\n",
      "highly 0.00823794530893\n",
      "small 0.00770277599141\n",
      "mean 0.0074032420216\n",
      "planet 0.00737306624896\n",
      "elegant 0.00734433531212\n",
      "loud 0.00730744420311\n",
      "nice 0.00627977463898\n",
      "desire 0.00624458633615\n",
      "disappointed 0.00575642148234\n",
      "tapa 0.00554756939682\n",
      "set 0.00507633773544\n",
      "rush 0.00500278248378\n",
      "-\n",
      "topic 3 : [ 0.  0.  0.  1.  0.  0.]\n",
      "staff 0.0772031843642\n",
      "waitres 0.0493445560783\n",
      "help 0.0403272405252\n",
      "wait 0.0384368523291\n",
      "waiter 0.0370709371347\n",
      "rude 0.0356741395887\n",
      "ful 0.0296968565496\n",
      "accomodate 0.0293574369657\n",
      "nice 0.0279431863451\n",
      "attentive 0.0260828305192\n",
      "waitress 0.0226723441116\n",
      "helpful 0.0146601115086\n",
      "incredibly 0.0142266541199\n",
      "waitstaff 0.0137468394467\n",
      "server 0.0130150320617\n",
      "friendly 0.0125717067372\n",
      "quick 0.0123508808958\n",
      "people 0.0114508306218\n",
      "ignore 0.00909452590034\n",
      "somewhat 0.0088081372836\n",
      "extremely 0.00871943847517\n",
      "manager 0.00744216452994\n",
      "bartender 0.00737702586113\n",
      "busboy 0.00732117516883\n",
      "super 0.00730486257626\n",
      "order 0.00720521694124\n",
      "care 0.0070494839193\n",
      "know 0.00664157096585\n",
      "welcome 0.00660308411987\n",
      "walk 0.00648860780558\n",
      "-\n",
      "topic 4 : [ 0.  0.  0.  0.  1.  0.]\n",
      "trip 0.091959823479\n",
      "definitely 0.0849531950418\n",
      "try 0.0501291897731\n",
      "worth 0.0362254259655\n",
      "return 0.0326979434499\n",
      "highly 0.0242371683217\n",
      "penny 0.0185759924495\n",
      "dessert 0.0151331099002\n",
      "think 0.0140856575725\n",
      "come 0.0133703176951\n",
      "long 0.0127548008194\n",
      "spend 0.0118345022666\n",
      "soon 0.0109176480329\n",
      "better 0.00948983103206\n",
      "money 0.0090599808112\n",
      "people 0.00825197610602\n",
      "love 0.00796428171862\n",
      "lot 0.00782668668707\n",
      "price 0.00775935348762\n",
      "unique 0.00769801984405\n",
      "buck 0.00752519367814\n",
      "waste 0.0071659166146\n",
      "enjoy 0.00645603159286\n",
      "danube 0.00623172442143\n",
      "best 0.00612619338085\n",
      "time 0.00592578670311\n",
      "left 0.00568519344786\n",
      "paid 0.00536302310669\n",
      "fantastic 0.00521233760758\n",
      "brooklyn 0.00490574661705\n",
      "-\n",
      "topic 5 : [ 0.  0.  0.  0.  0.  1.]\n",
      "wait 0.135058499725\n",
      "night 0.0606009517458\n",
      "reservation 0.0548348456286\n",
      "dinner 0.0298556930597\n",
      "experience 0.0259462710039\n",
      "time 0.0239117412196\n",
      "week 0.0180674283804\n",
      "table 0.0168619740945\n",
      "friend 0.0164889269062\n",
      "late 0.013320302745\n",
      "esca 0.0116333561339\n",
      "lunch 0.0102791478323\n",
      "party 0.00959605612475\n",
      "anniversary 0.00887685046039\n",
      "boyfriend 0.0082244828883\n",
      "seat 0.00773475558257\n",
      "hour 0.00757375182902\n",
      "great 0.0070747620793\n",
      "kitchen 0.00665434221375\n",
      "people 0.00660668622439\n",
      "crowd 0.00656452606585\n",
      "recently 0.00651347340568\n",
      "love 0.00625397789656\n",
      "past 0.00611412600149\n",
      "year 0.00572267023549\n",
      "bring 0.00556674626073\n",
      "long 0.00528291926174\n",
      "make 0.00525027461035\n",
      "friday 0.00468404131387\n",
      "eat 0.00447846341415\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "topic = 6\n",
    "rbm = RBM( n_visible=len(docs[0]), \n",
    "           n_hidden=topic, \n",
    "           mbtsz=50,\n",
    "           epochs=10,\n",
    "           eta=0.11,\n",
    "           mrate=0.8,\n",
    "           np_rng=np.random.RandomState(1234),\n",
    "           lambda1 = 0, lambda2 = 0, lambda3 = 0,lambda4 = 0, \n",
    "           p_A_vk = p_A_vk,p_s_vk = p_s_vk,p_Aj_vk= p_Aj_vk,p_sj_vk = p_sj_vk)\n",
    "rbm.train(docs[0:15000])\n",
    "rbm.wordPredict(topic, voc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684947721444\n",
      "0.672216844143\n",
      "0.678522571819\n",
      "0.654501216545\n",
      "0.29096809086\n",
      "0.402845376264\n",
      "0.191881918819\n",
      "0.223752151463\n",
      "0.20659515296\n"
     ]
    }
   ],
   "source": [
    "label = np.loadtxt('labels')[0:15000]\n",
    "result =rbm.run_visible(docs[0:15000],0)\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "print(precision_score(label[:,0],result[:,1]))\n",
    "print(recall_score(label[:,0],result[:,1]))\n",
    "print(f1_score(label[:,0],result[:,1]))\n",
    "\n",
    "print(precision_score(label[:,1],result[:,3]))\n",
    "print(recall_score(label[:,1],result[:,3]))\n",
    "print(f1_score(label[:,1],result[:,3]))\n",
    "print(precision_score(label[:,2],result[:,2]))\n",
    "print(recall_score(label[:,2],result[:,2]))\n",
    "print(f1_score(label[:,2],result[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
